---
layout: single
permalink: /collaborations/
title: "Collaborations"
---

{% include base_path %}

<div class="markdown-content">
  <h2>TL;DR</h2>
  <p>If you think I can be helpful for your project or you are looking for a project. Feel free to shoot me an email.</p>

  <h2>For undergraduate students</h2>

  <p>I have some ideas on projects in AI and Systems. They are in different directions and have different levels of maturity.
  Previous collaborations with more junior researchers have resulted in paper like <a href="https://arxiv.org/abs/2504.07174">HypoEval</a>. 
  If you are interested, feel free to shoot me an email with your background and your interest. </p>

  <h2>Direction that I am currently working on:</h2>
  <p>LLM inference. If you want to help out. Also shoot me an email with your background.</p>

  <p>Some other questions that I think about:</p>

  <ul>
    <li>
      <p>Non-volatile memory devices are getting very fast (>10GB/s). Can we improve AI/multimdeia applications utilizing these hardware/system innovations? 
      I think this is really interesting but I do not have a full project in mind. Here is a list of some related works on this <a href="https://docs.google.com/document/d/1D-MAjoe6-YUAyWtjk7-_N-0gC9uCLT_0nc7oHZ-EOM8/edit?usp=sharing">link</a>.</p>
    </li>

    <li>
      <p>Post-training has demonstrated significant gains in LLM performance. How can we:</p>
      <ol>
        <li>collect preference data during serving?</li>
        <li>design new metrics outside preference to optimize other things like retention rate?</li>
      </ol>
      <p>The first question is due to cost of collecting annotation. It is ideal if we can make self-improving LLMs. 
      I have an initial design about such a system.</p>
      
      <p>The second question is more about business metrics. 
      For example, if the only profit source is from ads, there will be a need to optimize ads click rate and preference at the same time. 
      This is more from my experience talking with LLM applications companies.</p>
    </li>

    <li>
      <p>In reasoning models, models will need to iterate through many options before getting the right onw. Can we compress the reasoning chain after thinking finished? 
      Note that this is different from the "overthinking" since LLMs will still need to think about many things before realizing it is the wrong direction.</p>
    </li>

    <li>
      <p>Improvement of AI ability in vertical domains. 
      I personally care little about "AGI" and am more interested in how they improve our lives practically. 
      Some examples that I think I can be helpful include AI for natural disaster prediction, AI for GIS...
    </p>
    </li>
  </ul>


</div>



